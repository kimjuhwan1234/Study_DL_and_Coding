{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 선형회귀 (25점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (2점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 빈칸에 들어갈 적절한 단어를 작성하시오.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀는 (?)변수 y와 한 개 이상의 (?)변수 X와의 선형 상관 관계를 모델링하는 회귀분석 기법이다.  \n",
    "한 개의 설명 변수에 기반한 경우에는 (?)선형회귀, 둘 이상의 설명 변수에 기반한 경우에는 (?)선형회귀라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답:  종속, 독립, 단일, 다중"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 (3점) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 빈칸에 들어갈 적절한 단어를 작성하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습하기 위해서는 모델이 예측한 값과 실제 값 사이의( ? )을(를) 측정해야 한다. 값이 작을수록 예측 성능이 좋음을 의미한다.\n",
    "\n",
    "오차를 측정하는 함수로 가장 많이 사용하는 방법은 제곱 함수이며, index i의 샘플에 대한 오차는 다음과 같이 계산된다.\n",
    "\n",
    "[![스크린샷](https://miro.medium.com/v2/resize:fit:606/format:webp/1*pHmlTbBjQERGJ4GbdJyNlg.png)](https://miro.medium.com/v2/resize:fit:606/format:webp/1*pHmlTbBjQERGJ4GbdJyNlg)  \n",
    "이 오류값이 작을수록 예측된 값이 실제 값과 더 비슷해지며, 두 값이 같으면 오차가( ? )이(가) 된다.    \n",
    "\n",
    "머신러닝에서는 모델의 예측 오류를 측정하는 함수를 ( ? )이라고 부르며, 위에서 정의한 제곱 오류 함수는 특히 ( ? )라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답:  차이, 0, loss function, MSE"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 (3점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 경사 하강법은 선형 회귀에서 비용 함수를 최소화하기 위한 최적화 알고리즘이다. 다음 중 경사 하강법의 특징으로 옳지 않은 것을 고르시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t경사 하강법은 비용 함수의 기울기를 이용해 점진적으로 최적의 해를 찾아간다.  \n",
    "2.\t학습률이 너무 크면 최적점을 지나치면서 수렴하지 않을 수 있다.  \n",
    "3.\t경사 하강법은 대규모 데이터셋에서도 효율적으로 사용될 수 있다.  \n",
    "4.\t경사 하강법은 항상 전역 최적해에 도달할 수 있다.  \n",
    "5.\t확률적 경사 하강법은 전체 데이터를 한 번에 학습하는 방법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 4, 5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 (2점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 중 경사 하강법을 사용할 때 학습률을 너무 크게 설정한 경우 발생할 수 있는 문제를 고르시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t최적의 해에 빠르게 수렴한다.  \n",
    "2.\t비용 함수 값이 줄어들지 않고 발산할 수 있다.  \n",
    "3.\t기울기가 작은 지점에서 멈추어 최적해에 도달하지 못할 수 있다.  \n",
    "4.\t반복 횟수에 관계없이 항상 전역 최적해에 도달한다.  \n",
    "5.\t학습 속도가 느려져서 최적해를 찾는 데 많은 시간이 걸린다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음과 같은 데이터가 주어졌을 때, 최소 제곱법을 이용하여 단순 선형 회귀 모델 $y = w x + b$ 를 구하시오.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|x|y|\n",
    "|---|---|\n",
    "|1|2|\n",
    "|2|2.8|\n",
    "|3|3.6|\n",
    "|4|4.5|\n",
    "|5|5.1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 평균을 구하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: \n",
    "- $\\bar x=$ 3\n",
    "- $\\bar y=$ 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 다음 공식을 사용하여 기울기 w를 구하시오.\n",
    "$$w = \\frac{\\sum (x_i-\\bar x)(y_i-\\bar y)}{\\sum (x_i-\\bar x)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: \n",
    "- $w=$ 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 다음 공식을 사용하여 절편 b를 구하시오. \n",
    "$$b=\\bar y-w\\bar x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답:\n",
    "- $b=$ 1.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 최종적으로 구한 회귀식을 작성하시오. \n",
    "- $y=wx+b$ 형태로 작성하시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: y=0.79x + 1.23\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 (3점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 선형 회귀 모델을 학습할 때 데이터 스케일링이 중요한 이유를 설명한 것 중 옳은 것을 고르시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t데이터 스케일링을 수행하면 모든 데이터 값이 0과 1 사이로 정규화되어야 한다.\n",
    "2.\t경사 하강법을 사용하는 경우, 특성의 크기가 다르면 학습 속도에 영향을 미칠 수 있다.\n",
    "3.\t데이터 스케일링은 선형 회귀의 예측 성능에는 영향을 주지만, 학습 속도에는 영향을 주지 않는다.\n",
    "4.\t스케일링을 하면 모든 특성이 동일한 영향을 가지므로, 변수의 중요도를 완전히 제거할 수 있다.\n",
    "5.\t데이터 스케일링은 단순 선형 회귀에서만 필요하고, 다중 선형 회귀에서는 불필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 (2점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다중 공선성이 선형 회귀 모델에 미치는 영향을 설명한 것 중 틀린 것을 고르시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t다중 공선성이 존재하면, 특정 독립 변수들의 회귀 계수가 불안정해질 수 있다.  \n",
    "2.\t다중 공선성이 심한 경우, 작은 데이터 변화에도 모델의 가중치가 크게 변할 수 있다.  \n",
    "3.\t다중 공선성이 있더라도 모델의 예측 성능에는 전혀 영향을 미치지 않는다.   \n",
    "4.\t다중 공선성을 해결하기 위한 방법으로는 주성분 분석(PCA) 또는 특성 선택이 있다.  \n",
    "5.\t다중 공선성이 심한 경우, 정규화 회귀 기법(Ridge , Lasso)을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음은 선형 회귀 모델을 학습시키고 사용하는 과정의 코드이다. 주석을 참고하여 코드를 완성하시오."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 예제 데이터\n",
    "X_train = np.array([[1, 80], [2, 60], [3, 90], [4, 70], [5, 50]])\n",
    "y_train = np.array([85, 75, 95, 80, 65])\n",
    "\n",
    "# 모델 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터\n",
    "dtest = np.array([[3.5, 75], [6, 55]])\n",
    "\n",
    "# (1) 모델을 사용하여 예측값을 구하는 코드\n",
    "pred_probs = model.predict(dtest)\n",
    "print(np.round(pred_probs, 3))\n",
    "\n",
    "# (2) 예측값을 0.5 기준으로 변환\n",
    "pred = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 로지스틱 회귀 (25점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (3점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 중 시그모이드 함수에 대한 설명으로 틀린 것을 고르시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 단조 증가 함수로, 입력 값이 증가하면 출력 값도 증가한다.  \n",
    "2. 연속이고 미분 가능하며, 머신러닝에서는 cost function을 최소화하는 B0, B1을 찾기 위해 필요하다.  \n",
    "3. 정의역과 치역이 모두 실수 전체이다.  \n",
    "4. 함수의 출력 값(치역)은 항상 0과 1 사이에 위치한다.  \n",
    "5. 입력 값이 0일 때 함수의 출력 값은 0.5이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (4점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 설명에서 빈칸에 들어갈 적절한 단어를 고르시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://wikidocs.net/images/page/165219/Fig_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function은 모델의 예측값과 실제 y 값 간의 차이를 측정하여 모델을 학습시키는 데 사용된다.  \n",
    "모델 예측값 Y_pred가 실제 값과 가까워질수록 (?)값은 줄어든다. Y_pred는 0 또는 1에 속할 확률 값을 의미하고, 선은 (?)의 값을 알려준다.  \n",
    "실제 값 yi가 1이면 예측값이 (?)에 가까워질수록 loss가 줄어들고, \n",
    "실제 값 yi가 0이면 예측값이 (?)에 가까워질수록 loss가 줄어든다.  \n",
    "즉, 예측값이 실제 값과 일치할 때 손실은 (?)가 되고, 예측값이 실제 값과 다를수록 손실은 (?)한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 손실함수값, 결정경계, 1, 0, 0, 증가"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (3점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 빈칸에 들어갈 적절한 단어를 작성하고, 질문에 서술형으로 답변하시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Logistic Regression에서 예측을 0 또는 1로 하지 않고 확률로 예측하는 이유는 세상에 불확실성이 있기 때문이다.  \n",
    "예를 들어, \"환자는 수술을 받으면 살 수 있다\"라고 말하는 것보다 \"환자는 수술을 받으면 80% 확률로 산다\"라고 말하는 것이 더 현실적이다.  \n",
    "하지만 경우에 따라 0 또는 1로 예측 결과를 제시해주기를 바라는 사람도 있을 수 있다. 이때는 몇 퍼센트 이상이면 1로 올리고, 몇 퍼센트 이하면 0으로 내리는 방식으로 예측을 결정할 수 있다.  \n",
    "(?)이 바로 여기서 적용된다.\n",
    "\n",
    "어떤 기업이 고객의 이탈 여부를 예측하기 위해 로지스틱 회귀 모델을 사용하고 있다.  \n",
    "모델이 예측한 고객의 이탈 확률이 0.6이라면, 기본적으로 (?) 0.5를 사용했을 때 이 고객은 (이탈/잔류) 중 어떤 것으로 분류될까?  \n",
    "만약 (?)을 0.7로 변경한다면, 분류 결과는 어떻게 달라질까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: \n",
    "- 빈칸: 임계값\n",
    "- 답변: 이탈, 잔류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (2점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: Multinomial Logistic Regression에서 각 클래스의 logit 값을 계산할 때, 어떤 값이 사용되나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 각 클래스에 대한 회귀 계수와 입력 변수 값의 내적  \n",
    "2. 각 클래스에 대한 확률 값의 평균  \n",
    "3. 각 클래스의 특성에 대한 고유한 함수 값  \n",
    "4. 입력 변수 값의 지수 함수 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 1, 4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 (3점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 중 logit 값과 softmax 함수의 관계에 대한 설명으로 옳지 않은 것을 고르시오. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logit 값은 모델이 예측한 각 클래스에 대한 실수 값이며, softmax 함수는 이 값을 확률로 변환하는 데 사용된다.  \n",
    "2. Logit 값은 클래스의 예측에 대한 신뢰도를 나타내며, softmax 함수는 모든 클래스에 대해 0과 1 사이의 확률 값을 반환한다.  \n",
    "3. Softmax 함수는 각 logit 값을 비교하여 가장 큰 값을 선택하는 방식으로 작동한다.  \n",
    "4. Logit 값을 softmax 함수에 입력하면, 각 클래스에 대해 상대적인 확률 분포가 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "정답: 3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 주어진 parameter와 input data를 통해 x가 각 class 1, 2, 3에 속할 logit 값 z1, z2, z3를 구하고, x가 어떤 class에 속할지 예측해보아라."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T06:37:27.061186Z",
     "start_time": "2025-03-18T06:37:27.000482Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# parameters\n",
    "B = np.array([[0.5, 0.2, -0.1, -0.2],\n",
    "              [0.3, 0.1, 0.2, -0.3],\n",
    "              [-0.1, 0.3, 0.5, 0.2]])\n",
    "\n",
    "# input data\n",
    "x = np.array([1, 150, 10, 5])"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T06:37:27.451670Z",
     "start_time": "2025-03-18T06:37:27.441597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# logit 값 계산 (z = B * x^T)\n",
    "z = np.dot(B, x)\n",
    "\n",
    "# 각 class에 대한 logit 값 출력\n",
    "z"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.5, 15.8, 50.9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답:\n",
    "- z1= 28.5\n",
    "- z2= 15.8\n",
    "- z3= 50.9\n",
    "- x가 속할 것으로 예측되는 class: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음은 문제 [2.6]에서 구한 z1, z2, z3 값을 확률로 만들어주기 위해서 softmax 함수에 입력하하고, 어떤 class에 속할지 출력해주는 코드이다. 코드를 완성하시오."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T06:37:50.283070Z",
     "start_time": "2025-03-18T06:37:50.276931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 주어진 logit 값\n",
    "z1 = 28.5\n",
    "z2 = 15.8\n",
    "z3 = 50.9\n",
    "\n",
    "# Softmax 함수 정의\n",
    "def softmax(z1, z2, z3):\n",
    "    exp_z1 = np.exp(z1)\n",
    "    exp_z2 = np.exp(z2)\n",
    "    exp_z3 = np.exp(z3)\n",
    "\n",
    "    # Softmax 확률 계산\n",
    "    sum_exp = exp_z1 + exp_z2 + exp_z3\n",
    "    prob_z1 = exp_z1 / sum_exp\n",
    "    prob_z2 = exp_z2 / sum_exp\n",
    "    prob_z3 = exp_z3 / sum_exp\n",
    "\n",
    "    return prob_z1, prob_z2, prob_z3\n",
    "\n",
    "# Softmax 함수 적용\n",
    "prob_z1, prob_z2, prob_z3 = softmax(z1, z2, z3)\n",
    "\n",
    "# Softmax 확률 출력\n",
    "print(\"Softmax 확률 - 클래스 1:\", format(prob_z1, '.10f'))\n",
    "print(\"Softmax 확률 - 클래스 2:\", format(prob_z2, '.10f'))\n",
    "print(\"Softmax 확률 - 클래스 3:\", format(prob_z3, '.10f'))\n",
    "\n",
    "# 예측 클래스 (확률이 가장 높은 클래스 선택)\n",
    "predicted_class = np.argmax([prob_z1, prob_z2, prob_z3]) + 1  # 클래스는 1부터 시작하므로 1을 더해준다.\n",
    "print(\"예측된 클래스:\", predicted_class)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax 확률 - 클래스 1: 0.0000000002\n",
      "Softmax 확률 - 클래스 2: 0.0000000000\n",
      "Softmax 확률 - 클래스 3: 0.9999999998\n",
      "예측된 클래스: 3\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 분류 알고리즘 (25점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 로지스틱 회귀에 대한 설명으로 옳은 것은?  \n",
    "1. 종속변수가 연속적인 값을 가질 때 사용하는 회귀 모델이다.\n",
    "\n",
    "2. 예측값이 0 또는 1 사이의 확률로 표현된다.\n",
    "\n",
    "3. 다중 분류 문제에는 사용할 수 없다.\n",
    "\n",
    "4. 선형 회귀와 동일한 비용 함수를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 랜덤 포레스트(Random Forest)의 장점으로 적절하지 않은 것은?  \n",
    "\n",
    "1. 과적합 위험이 적고 안정적인 성능을 보인다.\n",
    "\n",
    "2. 범주형과 수치형 변수를 모두 처리할 수 있다.\n",
    "\n",
    "3. 계산 비용이 낮아 대규모 데이터에서도 빠르게 동작한다.\n",
    "\n",
    "4. 이상치나 결측치에 대해 비교적 강건한 성능을 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 문장의 O/X를 판별하시오. \n",
    "1. 나이브 베이즈는 베이즈 정리를 활용한 확률 기반 분류 알고리즘이며, 각 특성들이 서로 독립적이라고 가정한다.\n",
    "\n",
    "2. SVM은 선형 분류만 가능하며 비선형 분류는 불가능하다.\n",
    "\n",
    "3. 로지스틱 회귀에서 시그모이드(Sigmoid) 함수는 예측값을 0과 1 사이의 확률로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: , ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: SVM에서 마진을 최대화하는 결정 경계와 가장 가까운 훈련 데이터 포인트를 무엇이라고 하는가? (단답형)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 (5점)\n",
    "문제: 어떤 데이터셋에서 새로운 데이터 포인트 P(4,3)이 주어졌다. 기존 데이터 포인트와 클래스는 아래 그림과 같다. k-NN 알고리즘을 사용하여 k=3일 때, 유클리드 거리를 기준으로 새로운 데이터 포인트 P(4,3)의 클래스를 예측하시오. (단답형)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IMG_1.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASoAAAEGCAYAAADSVNhiAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAACHCSURBVHhe7d0NWJRlojfw/3l9F/Z4MW2XQ+4BTitsHdA2XE4YGi8oBkpiYoiFmo27bqgpfeFHwOaiVkL5Ua+SWVptWCotCqHgYkxNwSElbFmoBeeyoMMCLTGealjPwnm5fO9n5gYBZ5iB1B5m/r/rupe57+cZ1OXu/9wfz8P800UBREQq9r/kVyIi1WJQEZHqMaiISPUYVESkegwqIlI9m7t+7e1fyVdERNfG+PH/Il9dzm5QXafxkjUi53xn7mS/oRFR+s5QQcWpHxGpHoOKiFSPQUVEqsegIiLVY1ARkeoxqIhI9RhURKR6DCoiUj0GFRGpHoOKiFSPQUVEqqfCoOrClx9/gE++7BKvTTj1RjbePG2yHhoWI4q3ZaP4nKwO07nj2dh23ChrP6Bzx7FtWy5OnZd1Gv0ufIlPDGfw5QWl8n36uPtQ4UPJbXj7N/fiZMwfsH8x+r32kcelHhFotcV4t6wD2ulRmDUlEF5j5DGLj/D0jPVAVgWeDJdNolOcM3wq/gRbfPCLqECMk7VTWyOQhm0wZNwhW2wQf4fObzvRLatD84TXOC94yJpVF9r+VIziMiP+CxpMuH0W4iIH/TsqNyMq/Uusfus13Pevss1CCfRT+M+/y6pdXvhZWCgmjJXVq8gVH0puO7Qci/c6vmDdvMpGH7Xnr4fw4P3vYrblZ9q/vw/9fuXiWWCagd8su6Ovn7oKRw8l/yBB1fbOeqQebJK1XlFYn7cGtzkTVD1f4u3HlmNPw4/gM04D8/k2dPoswM49qbit769tK6isbWVeWvh4DYyMS3++lVNB9dVRpD16CF+KqDJ/bULnGC/L36eX5e8lgsLaNvD7K/+G4vRHsO1PHrhteih8fmzGWcMHOPfPdyP792mY1vvvsBtU1v+f9nxl69/Snz/u+7/bkGC/D1wxLvnbEy504vw/lNG9PV/haOpKnIod2Ect/adUVvrMQvYHmZg2wqCyfM/P1+DQq4vFZdW1qPO3J1wwoe2fZ+HJl/bixb6yDLfKw46ce20d9vx1OrIL/ohDeX/A8eK38OCPjuJ3uz5yanRz89K9lvcNLP1CxFn/sgDZlvfuhS5A1GdmDvieT87s3zbw+58/vhXbPrsNT+X/ATs3pmH9+mewv+gtrB53HGnbPnBylGbv39K/XJuQck1ixDw4pL5twme1n/YrZ/HVf8tj/UzLqIDhg34la5Y8MlImmNrFl6/a4I6rAD/cGtUYDcaN0/Yrg6dF9nyG4sI2RK7pN+rwmIClKQuA0uP40DLvV7sufPLxZ/CavRCRP5FNijETcM99M4Dyj/CJbKIf0nmUZN6PNQ+tulTSsnG47COc+ri3fIDPvoIYSTrXe0fs7BG8+ScvMT4/iYLyTtnoPkbfrt9fa1HXGYjgiZ6yQQoKxr/jDD5zYvH8fzrP4/x504DS6ewQ5irz8BQdvmeoqcZA5/bei6gZEfbLbw7ZWZMjx3xw327rqL1/efFpZQQsy5q7cbNy5g1a61uuhs6P8HRaLroW7MCLy3xRlvkI3v5SHnMTKgkqZe2o9z+ue7HHYdhMwM8GrNcIY73giU6Iqa5DX765EgsS5g8oL1QrawWX/gO/fH3hSvLEbbf/Ap0n8zHg4qisvR14F4iKcnoaqiziDphiDC4uuJ5xTZz/CG9uy8Y2R+XZQ/iTGOecLVHql3ZnlfWkvouFUtLFz3UAI3IfuxeLk1Yht1E22dDdeBRpv1qPshvW4PmUX2DCfbuQHWPCngdXYn+t+4ysVBJUt+Gxgndw1FJexlJlvWdI52H6HhN1W/9xPxkurp6vXqpnx8qTh9SFTsuI7Dy+61GqnQNHacrAqK9t4O7guLszsPrnH2Jjwv3Y+NpRlB16ERt/sxx7vp6Bp1JmODkNph+cVyBm3B2FIFt7CFGZsk/3lrX9LkA+mLYkBasfWoZpN8imPl04f/Y49qy7F3f/6kW0hT+Doy8txgTLbrAXpmW8hReVjaaH78LdKzbjbYMRnUr/c2E/zK6fsuVbNsvO7oWDXb8L72LjnB3wFkPyRydbmyzOvoLFK04hIe813GdZPLa/69fkxFayU7t+Yqq5Jykb5bJm8d/n0fZtF7xu8IFmwO0Sg3b9FD2dOFd6EAWVZ/DpP3wxNXQ2EhLvgE//lHKw65c7ZgZm/NulnUZbbklIw1xlfnKVueSu3wgN2X8c7vp14dS2pdj/7SwsW7UMkf86aJlD6j5/BsV7X8GrbVHYt3t0j5zVuev3fYydjtlRnSh4+10x0eslfrBHjqJt8t2IuaY7XKFYPWj94lDadNEeCN0Lg9pt7SqO8cLNcSuw/umX8cb2TKxePCikhjQOU1c9gyeWzMa02+8YsgT1X7CnYblsCmevbP1IvuNK8MS09SK4nl5hN6QUHuNCkZDxMo6P8pByxg8XVJ1GnDIcxf7euf6TK7F4nQgbedg+T0QuX4ObxUhDl/4KygwfoGDbcqSVaS07f87cCPf3cx+hXLyvvPQQ9sg//+l192Ox7hV8Js+5VpR7yhZvcObfPZgnJtw+A5FRjsvNl00tyFmX3WZgo9hdJmj7xNLPCl7r18dG9LOmHySoPH8ehblTPHHuY+WObMU43ByzBI+umu3clWHCYuzPewYx//MBXn0pB29/EYhHc17Gg0HyuF1a/Pvdd+O2H4uQVLaWa7+E5cZurbLOIEY2m5fg3yznXUPKPWWmIXb5pqzF0YJduMfVL5kqZXmUqvdiaqe8bePq5i1G93N/Zrb0s3OWp2PG4Reijz36mxmiF9Jwjd5HaByytUblPIdrVB+/iMXbDbLSj901KsXld4kPvV5n2ycv3ottH8qKs0S473xuwVWdIrjiGpWlH7QtxlOJDm5H9rkVkUFORpCDNSq1/nyvJkdrVAwqOxwG1ddGlH823EG812XP3VmCqnQaXtyZOGQn8/ixFl7yfd2dI7jva4wXxv3E/nrHleCyQeVwU2WYHASVWn++V9MoDCrrw7am8dNw24Tz6g2qK8T2c4+Xm7BkF7Lnq/t66bJB5dQ9dYE2dmbtUH57QlUHtJaLlq1dP/czCoNqoO5vTej+0aXRhPOUe5w6xSBGvHcENyVZrmpiBDTOa/Repa41Vwyqa2Hkfdx1OAoq1d+e4PGTkf4AlV+rMrKQUniIgGNI0bUw8j7uPkbffVRE5HYYVESkegwqIlI9BhURqR6DiohUj0FFRKrHoCIi1WNQEZHqMaiISPUYVESkegwqIlI9uw8lExFdSyP67QlDvYnIFvYbGilHfYdTPyJSPQYVEakeg4qIVI9BRUSqx6AiItVjUBGR6jGoiEj1GFREpHoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItVjUBGR6jGoLMwo3TAVugONsi60n0Dm3SGirUU22NBjRuXLK7AoOgTTwkIwfbYO2w0d1mPmCmTOicH2GmuV3FhPFbYrfWRpLlplEw0Pg0owFa5FZusaZD8QgG5zIwwvrMDc+ekobZcn2CRC6qkEpB7TYmFOMYpPFCA78Tq8v2ERtlZ2AZoI/HZjJN5Pz0Jdj3wLuaVuQx7yL4gXxjwUGa1tNDwMKnG1e313PRY+roMvuvC+CJ/flWtwf84rWBUoz7Hl8wLsLf8lNh/KwsJJftBqAxC+MgsrwztQZPjYcopH+Br8+sY87CqUoyxyQ6JPleqhuSdd9KcWHCmqle00HAyqygLkeyUhPlSpeCI2qwYfHtmBJaF+8LCcYMdNOuTqdyBWI+sWGnhfL760fy3GWwpvxCdGo+7gYfBC6qbaC5Fv0CA2NgnzEibDfKIY1RxhD5vbB1Xd6QpoIqejb/A0Rn4dkQbU1gG+gZNEZFl5TInAlOYKVLfJBnIrxoJc1GniEBsCaCPnItgspoGGLnmUnOXmQdWCujozQoODZP37aTqwCb9vDcOvFk6ULYJ2Em71acDZc7JObqQB751sgW9iAoKV6vhoS2AZSt9Dt+U4OYtTPzEM9xzrKSsjZUbdyzro9nQg/rkdiB8vmy00uE4Mr0wmrlO5nTMFONLsh9kzey9c3pgZFyaS6hCKhtyoocHcPKga0fS5fDlS5lrsXRGD5MLrsGpfATIiByxa9fnOzOG+u6kuK4FZG4HJ4zssFyrLxeqWMDG6qkVR6RC3vdBl3DyoAuB/k3w5Esq9UvfpcGxsKg6/k4Mlt9oOKYXveG/5itzCBT3yC81iKJ2H1DkxmNtbluagThw2FhZwg2UY3DyovKH1FeOq5pFc3bpg2JqCUv9M5L6QBH+7W4TKqE0D759+3+kljSbd5SUw9EzGuuM1OFU1qLyUBE1zHorOyJPJITcPKk8E3RIAY02tU4ubxj1zMS1dbz33wnv4ox6YMjNMXDUvDe2txYzu3i3o5i/Q0COG+0Pdk0UupgNFR0TnCE3AzAHrlZJoT/Qxo7SsSjaQI26/mO4fHg3f8jJUKncOD6kF1adbEBUTYb2/yvS15XGI6u1zLw3r+0oy8uWzEsaSPBij4zBzrLVObqC5BEU1QNTCOGhl00ATcWecH8yFeTA47Hek4Ee6K1e/h2JwLKYM+xKHWEe6cAJpUWWYadiBWGdDR3nGa3YGsKMM60JkmwvjR7rTSPEj3R3yRvwTqeh6Pgul1tvJbaupgiEqZlgjo6YDO1Eano6VbhBSRFcTg0rhr8OWDD/UnWywv1YVnolTz80Z+rGa/tr1+GNrHLI2RPfdpU5EI8OpH10x7Dc0Upz6EdGox6AiItVjUBGR6jGoiEj1GFREpHoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItWz+wgNEdG1NNQjNHzWj64Y9hsaKT7rR0SjHoOKiFSPQUVEqsegIiLVY1ARkeoxqIhI9RhURKR6DCoiUj0GFRGpHoOKiFSPQUVEqsegIiLVY1ARkeoxqCzMKN0wFboDjbIOmAxZSJ49FdPCQjAtIhLJz+ph6pEHbSlPt547qGSWi2NNudBFrEBRu/VUcjM9VdgeLfrD0ly0yiYaHgaVYCpci8zWNch+IEDWV2BuehUCHn4DR0+U4fDmGJjFObrnay3Hbem+0A3c9CD2ifOL+5V1U8VBfx2yV3+H7ZkFMFlPJzfSbchD/gXxwpiHIqO1jYaHQSWudq/vrsfCx3XwlU0et8xBRk4uMuZNhK/WG/7RmdjygB9MNTV2r4gd7S3AmOugFef3LxoP63HfpFTEG3fi9TPWOrmLLrxfqofmnnSsCmzBkSL7Fzuyj0FVWYB8ryTEh8q6oAlMEHWNrFl1KdM+jQae1qptAX59YXeZMWGIT7wO+fl6iLEXuYv2QuQbNIiNTcK8hMkwnyhG9VBLCGST2wdV3ekKaCKnI1DW+3SbYTJ1wPR5FUpfTkFanhaPPJEArTw8WFNzgwijIWMMgeER0BgqUC3r5PqMBbmo08QhNgTQRs5FsFlMAw1d8ig5y82DqgV1dWaEBgfJej+nt2LunBjMXbwCma82IGjlOsy7UR6zRRkmlaRYF9HviMTc5enI/9RsPdYrMAShPfUi1GSdXFwD3jvZAt/EBAQr1fHRlsAylL7HUfUwceonhuGeY22MhCKzcKqqBqc+Oo3iN5KhydNh1nL7uzZT1l5aQD+ck4JYz4+xfXkCttfIExRjlaljC1q5ou4ezhTgSLMfZs+cKBu8MTMuTCTVIe4AD5ObB1Ujmj6XL+0R0zntpCRsztbBtz4PRfWyfRAPzaUFdP/QJDzyUgEywjuQf/DEoKunGeZBAy1yTdVlJTBrIzB5fId1GUEU3BImRle1KCptkWeRM9w8qALgf5N86cikX4oO1oI20deco8GUUHElbf0aA9/iBx9v+ZJc1wU98gvFFcmUh1RlCaG3LM1BnThsLCwA71RwnpsHlRgB+YpxVXO/q1t3A4o2peNgk6z3qqlCJSYiyF/W++lursDBkgZZ69WFujrR5nuD+FOkti/EGM4PvuNlnVxWd3kJDD2Tse54jXUJoX95KQmaZjE6560qTnPzoPJE0C0BMNbUXpqeefiJYPkYux5Kwd7KRstwvakyB6lP5sEjLkUuqDdg7/wQpOmtuzddTcV4a9MyLHpWXCXFkMtkakTl7mQ8Y/DGwiVzIG+lAs7Vw+gzGRPtbR2Si+hA0RE9EJqAmbYuSqI90ceM0rIq2UCOuP1iun94NHzLy1Cp3DlsoUH4xgLsW+IJw8YEy3B90UY9uu/JweGNEeKo0CZGV+3RuOsO6yK8JjILh19JRdDZnXhwvjLET0Bm+Q1Y9VoB1oVYThG6YCg5Ad+4mMtvhSDX0lyCohogamGcndtZJuLOOD+YC/Ng6Ot3NBR+UrJy9XsoBsdiyrAv0bnFo+7StZiuj8GHz/UbLTnSnofk+XrMe+cVxLvo1I+flEwjxU9Kdsgb8U+kouv5LJQ6uRtXfUaPqOg7nQ8pmGHYnYOulekuG1JEVxODSuGvw5YMP9SdbHDqRrzwjBpkxw59F3p/3fUlqNZmYIt86JmIhodTP7pi2G9opDj1I6JRj0FFRKrHoCIi1WNQEZHqMaiISPUYVESkegwqIlI9BhURqR6DiohUj0FFRKpn9xEaIqJraahHaPisH10x7Dc0UnzWj4hGPQYVEakeg4qIVI9BRUSqx6AiItVjUBGR6jGoiEj1GFREpHoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItVjUFmYUbphKnQHGmW9BQeXhmBa2KCyNBet8ozLfFOBvQ8nYNYdyrlTMWt5Fgzt8lhTLnQRK1DUWyc3UIHMwf0nOgEpL+hh6pGnkPOUX/My2N/+1iZfuYeOguSLU+9/42KLrF+8WH/xpfhfXnyi+OuLHR39yn/9Qx4f5Lvyi7+765cX4548fPFsqzjvXPnFlx6Nvjj1rk0X/+Pv1lNa3kq6GLnq6MUOa9UluVu/GZroE7f370N/vXg2P/VinGhL2Fsvz6FejvoOR1Q9VXh9dz0WPq6Dr2wCOtDWBnhqvKHV9ivXe8rjAzUdy0FlcBYOP5WEQB9x3k0RWPXUGoSbCmCosZ7jm5SKeONOvH7GWif3cKkP+SEwcQfWxwKt5VX2R+ZkE4OqsgD5XkmID5X1PgEIuFG+dMB/yWG8+9wcaGTdQnODpd5hMlvrY8IQn3gd8vP16La2kNsx4zulO9zoB29rAznJ7YOq7nQFNJHTESjrFm1foBGe8Bgj6yNhrEEdxFX05kvxFRgeAY2hAtWyTq6vy9wBk0mUtgYUbdVh69kIZKyMhoc8Ts5x86BqQV2dGaHBQbIu/T/lfxqwK9G6CDp99jAXQXsacfCZ/WgNfRD3TpJtisAQhPbUo6lZ1snlGTbFYO4cUeYvwtbCVgRGJWDKpTUGchKnfiJ8PMcOWnvyTcKLJ8pQrJR3DmPLAxPRkb8Wc1MKYJKn2GWuxd6HFmGXKQE7n0uAVjZbjNWIcVoLWh1+E3IVsTtqcKpKKafx7qE0BJSvxYLkIXaPySY3D6pGNH0uX/Y3xhOa3gV0n4mIeiALh/fq4HtmP/5QL8+xwfxpDpLn6HBs7BrsO5SJ8AGLVr3MMMtlK3Inok/dlIDNm5Ogqc9D0RD9iC7n5kEVAP+b5EtHbg1DsBgNtXXI+iDm8nQsWl4IzeMFKHhBh2CbIaXwgw9XUt3XePHzH6IfkW1uHlRixOQrxlXNLbIu9JhhPJaHysE3Z9ZbF8dthswFPZ7ZcAIBGYexMzHA/kKpZZHeD77jZZ3cjvkvf4YRExF0s2wgp7h5UHki6JYAGGtq+90y0IHq/CykLk/B3spGy45NqxiqZ67vvzjegL3zQ5Cm77K8o7u8BIaeMESFwrrD0798Yz3H4lw9jD6TMXHAwhW5sr5dP1OLuABuRvImPbRxKZjnI08gp/ADSI05WLCsEY/odyBqrGzrboFhz2bsPVaFJmU9yUOD4HmbkL0uGlrlloW2XOgW/BnL5XtaDyzCgt0NlrdeJjAVR99UbibtgiF9Knb5H8bRlRPlQdfCDyDtT3mEJgWlsmahCUDUrzbjt0smQ/N9bn1xQY76DoNKjKCKHorBsZgy7Et0bvGou3Qtputj8OFzc5y/H6Y9D8nz9Zj3ziuId9GpH4OKRspR3+HtCfBG/BOp6Ho+C6VO7sZVn9EjKvrOYdy0Z4Zhdw66Vqa7bEgRXU0MKoW/Dlsy/FB3ssGpx1vCM2qQHWv7uT9buutLUK3NwJYHAmQLEQ0Hp350xbDf0Ehx6kdEox6DiohUj0FFRKrHoCIi1WNQEZHqMaiISPUYVESkegwqIlI9BhURqR6DiohUz+4jNERE19JQj9DwWT+6YthvaKT4rB8RjXoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItVjUBGR6jGoiEj1GFREpHoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItVjUFmYUbphKnQHGmVd6OmA4VkdZkWEYFrYVMxangVDuzzmUAsOLhXvW5qLVqXalAtdxAoUOf1+Gv0qkBmm9J1+JToBKS/oYeqRp5DTGFSCqXAtMlvXIPuBAGtDTyMOLo9BWrkfVu4rRvE7u/Hr6/RIW7YZlRespwzFbMjB60ZZUfjrkL36O2zPLIBJNpF7iNpUhuITSilG7uqfo/HgWiTvb5BHyVkMqp4qvL67Hgsf18FXNpmOZWGXMRqbD2Vh4SQ/aH3CsGTHPmQ/GA3//y1PsudCBXY/W4vQKBl6km9SKuKNO/H6GdlAbsFT4w2tVil+CEzcgfWxQGt5lXWkTU5jUFUWIN8rCfGhsi6mbaUFVdAkLkOsRjYpxgQgKjECvh6ybpMZlc9twn9EpmN5sKdsk8aEIT7xOuTn69Etm8jdmPGdWXy50Q/e1gZyktsHVd3pCmgipyNQ1tHTgLP1QPiUybLBeebyrXjmdCR++1gEvGRbf4HhEdAYKlAt6+T6uswdMJlEaWtA0VYdtp6NQMbKaAx5vaPLuHlQtaCuzozQ4CBZF1pb0IgABFxfi4MbEjDrDmUhdCoWPJyDym/kObY05WLNho8xMysT4WNl22CBIQjtqUdTs6yTyzNsisHcOaLMX4Stha0IjErAlN41BnIap349gOfYQdM0EVV7UzLRFJmFN46X4egbaZjyt/1IXZyFOls7NuYKZD60E1i9D+tCZJstYzXwFOHYyhV1txG7owanqpRyGu8eSkNA+VosSJa7weQ0Nw+qRjR9Ll8OEvz4PmTMmwhfrTd8JyUg4+kH4WvKw7HT8oReyg5hSgreD0rHljiNdZivFHOXOPadeG1G94BwM8OsrFOQm/GE5qYEbN6cBE19HorqZTM5xc2DKgD+N8mXvXz9RKv4Mn7QcqeYtgWLL12DR1St5fij6HTdlVlYpAzxZUn+fSPw+X4kz0lG/oDLpx98uJLqvsaLn78YVbd1yDo5xc2DyhtaXzGuam6RdWHMLxEaCtTVDbrX5dMq1Ckh81NZ73WjDrmWof3AcvThiSLcUnG06jCW3CjPbftCjOH8RAjKOrkd81/+DCMmIuhm2UBOcfOg8kTQLQEw1tT2u2XAG/GPPAj8PgWpL1egSUzjWs/kInV9Lrri0nG/ZXuwAXvnhyBNL6Z3w3GuHkafyZiolXVyeX27fqYWGI9tRvImPbRxKZjnI08gp7j9Yrp/eDR8y8sG3nE+KQVvvKaDhz7dMp1b8Ggeuu/JweGNEbDcWtVWhcr2aNx1x+BF+KF0wVByAr5xMZduhSCX17frN2cudC/UwH917qV+RE7jR7qjA0UPxeBYTBn2JTq3eNRduhbT9TH48Lk5zt8P056H5Pl6zHvnFcS76NSPH+lOI8WPdHdITPWeSEXX81kodXI3rvqMHlHRdw7jpj0zDLtz0LUy3WVDiuhqYlAp/HXYkuGHupMNTj3eEp5Rg+xY56d93fUlqNZmYEvvQ89ENCyc+tEVw35DI8WpHxGNegwqIlI9BhURqR6DiohUj0FFRKrHoCIi1WNQEZHqMaiISPUYVESkegwqIlI9u4/QEBFdS0M9QsNn/eiKYb+hkeKzfkQ06jGoiEj1GFREpHoMKiJSPQYVEakeg4qIVI9BRUSqx6AiItVjUBGR6jGoiEj1GFREpHoMKiJSPQYVEakeg8rCjNINU6E70CjrXWg6lo7k2VMxLSwE06ITkHagVpw1FDPqXtZhelg6Ki3VCmTOicH2GstBcmc9VdgeLfrR0ly0yiYaHgaVYCpci8zWNch+IMBSbzqwDIuebUHwpsMoPlGM3MdC0LRHhzUHWyzHB+jpgulMHjIXxyD51Vp0y2ZoIvDbjZF4Pz0LdT2yjdxStyEP+RfEC2MeiozWNhoeBpW42r2+ux4LH9fBV6l/U4GDeV341b5cPBIeAK3WD4HzMvHbJX4wluovvyIa9yE5JQeNIVtx+Kk5stHKI3wNfn1jHnYVdsgWcj9deF/0G8096VgV2IIjRbWynYaDQVVZgHyvJMSHyvr1Ecg4XoBVk2Rd0l6vAdo7YJL1PpNScLSiHLlPRMN/rGzr4434xGjUHTwMXkjdVHsh8g0axMYmYV7CZJjFCL2aI+xhc/ugqjtdAU3kdATKum1dMP6lAQiehCDZMsAY+dUGjykRmNJcgeo22UBuxViQizpNHGJDxMUuci6CzWIaaOiSR8lZbh5ULairMyM02Gb89DGXb8I2vTcWLpkDD9nmNO0k3OrTgLPnZJ3cSAPeO9kC38QEBCvV8dGWwDKUvndpLZOcwqmfGIZ7jvWUlcuZStOxaMN78H1sH9aJTjZ8GlwnZo0mE9ep3M6ZAhxp9sPsmRNlgzdmxoWJpDqEonbZRE5x86BqRNPn8uVgPR0o3RiDuZsa8H+yirFviXVHcKS+M3O4726qy0pg1kZg8vgOy4XKcrG6JUyMrmpRVGpjB5nscvOgCoD/TfJlfz2NOLg8Bplno7HzRAEyorzlgZHzHf/9vweNIhf0yC80i6F0HlLniAteb1magzpx2FhYwA2WYXDzoPKG1leMq5oHXt2M+1Owqz0J+w6lI/x62ThiyqhNA++f2p9ekuvpLi+BoWcy1h2vwamqQeWlJGia81B0Rp5MDrl5UHki6JYAGGv63aipLICWtEAbHQnfby4N2XuL2XJiA/bOD0Ga3onpXPMXaOgRw/2htxXJpXSg6IgeCE3AzPGyqT/RnuhjRmlZlWwgR9x+Md0/PBq+5WWoVO4ctuhAW5sYsb+dcmm43q9sPy1OaatCZXs07rrD8SjJWJIHY3QcZl52jxW5rOYSFNUAUQvjoJVNA03EnXF+MBfmwdDX72go/KRk5er3UAyOxZRhX6Jz60jdpWsxXR+DD59zcLuC8ozX7AxgR9kIdwxHF35SMo0UPynZIW/EP5GKruezUDr0U8d9qs/oERV9p8N7qpoO7ERpeDpWukFIEV1NDCqFvw5bMvxQd7LBqRvxwjNqkB3rYNrXrscfW+OQtSEaGtlERCPDqR9dMew3NFKc+hHRqMegIiLVY1ARkeoxqIhI9RhURKR6DCoiUj0GFRGpHoOKiFSPQUVEqsegIiLVs/sIDRHRtTTUIzQ2g4qISE049SMi1WNQEZHqMaiISPUYVESkegwqIlI9BhURqRzw/wFGEcDsMYYi0QAAAABJRU5ErkJggg==)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 분류 모델의 성능 평가 (25점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 중 F1 Score가 가장 높은 경우로 옳은 것은? \n",
    "1. 정밀도 = 0.9, 재현율 = 0.1  \n",
    "2. 정밀도 = 0.5, 재현율 = 0.5  \n",
    "3. 정밀도 = 0.7, 재현율 = 0.7  \n",
    "4. 정밀도 = 0.8, 재현율 = 0.2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 다음 문장의 O/X를 판별하시오. \n",
    "1. 재현율(Recall)은 전체 예측한 Positive 중에서 실제 Positive의 비율을 의미한다.\n",
    "\n",
    "2. ROC 곡선에서 AUC 값이 1에 가까울수록 모델의 성능이 좋다는 것을 의미한다.\n",
    "\n",
    "3. 혼동행렬에서 FN(False Negative)은 모델이 실제 Negative를 Positive로 잘못 분류한 경우이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: , ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 아래 그림은 혼동 행렬을 나타낸 것이다. 빈칸 (a)~(d)에 알맞은 말을 쓰시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IMG_2.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답:\n",
    "- (a):\n",
    "- (b):\n",
    "- (c):\n",
    "- (d):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: ROC 곡선 그래프에서 x축과 y축에 각각 해당하는 지표는? (단답형)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 (5점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 어떤 모델이 100개의 샘플을 예측했을 때, TP=40, FP=10, FN=20, TN=30이라면 정확도(Accuracy)는? (단답형)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
