{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:59:19.889470Z",
     "start_time": "2025-05-12T11:59:18.204155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "import T4sigWGAN as T4\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:59:20.363310Z",
     "start_time": "2025-05-12T11:59:20.052608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_dataset = T4.StockTimeSeriesDataset(T4.args.window_size)\n",
    "train_size = int(0.9 * len(total_dataset))  # 90% for training\n",
    "val_size = len(total_dataset) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(total_dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=T4.args.batch_size, shuffle=False, num_workers=2,\n",
    "                              drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=T4.args.batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:59:20.606458Z",
     "start_time": "2025-05-12T11:59:20.395134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Encoder = T4.LogSigRNNEncoder(**T4.encoder_config).to(T4.args.device)\n",
    "Decoder = T4.TimesFormerDecoder(**T4.decoder_config).to(T4.args.device)\n",
    "Supervisor = T4.ModernTCN(T4.supervisor_config).to(T4.args.device)\n",
    "Generator = T4.LogSigRNNGenerator(**T4.logsig_config).to(T4.args.device)\n",
    "Discriminator = T4.tailGANDiscriminator(T4.discriminator_config).to(T4.args.device)\n",
    "model = T4.T4sigWGAN(Encoder, Decoder, Generator, Supervisor, Discriminator, T4.args.batch_size).to(T4.args.device)\n",
    "trainer = T4.FinetuneTrainer(T4.args, model, train_dataloader, val_dataloader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 22759902\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-12T11:59:20.622550Z"
    }
   },
   "source": [
    "stage = \"Pretrain_1\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('RMSE_loss_for_ER')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]C:\\Users\\USER\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:744.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "  6%|â–Œ         | 31/500 [04:33<1:08:00,  8.70s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stage = \"Pretrain_2\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('SigW1_supervisor_loss_for_GS')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stage = \"Finetune\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('SigW1_generator_loss_for_GS')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_fake = model(600)\n",
    "stacked = torch.stack([total_dataset[i] for i in range(600)])\n",
    "x_real = stacked\n",
    "T4.plot_summary(x_fake=x_fake.detach(), x_real=x_real.detach(), trainer=\"T4sigWGAN\", G=\"LogSigRNN\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 1.5), dpi=400)\n",
    "plt.plot(x_fake.detach().cpu().numpy()[1][:, 1], label=\"Fake\")\n",
    "plt.plot(total_dataset[1].detach().cpu().numpy()[:, 1], label=\"Real\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# metric_iteration = 5\n",
    "#\n",
    "# discriminative_score = list()\n",
    "# for _ in range(metric_iteration):\n",
    "#     temp_disc = T4.discriminative_score_metrics(ori_data, generated_data)\n",
    "#     discriminative_score.append(temp_disc)\n",
    "#\n",
    "# print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))\n",
    "#\n",
    "#\n",
    "# predictive_score = list()\n",
    "# for tt in range(metric_iteration):\n",
    "#     temp_pred = T4.predictive_score_metrics(ori_data, generated_data)\n",
    "#     predictive_score.append(temp_pred)\n",
    "#\n",
    "# print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))\n",
    "#\n",
    "#\n",
    "# T4.visualization(ori_data, generated_data, 'pca')\n",
    "# T4.visualization(ori_data, generated_data, 'tsne')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
