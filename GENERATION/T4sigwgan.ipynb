{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import T4sigWGAN as T4\n",
    "\n",
    "gc.collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_dataset = T4.StockTimeSeriesDataset(T4.args.window_size)\n",
    "train_size = int(0.9 * len(total_dataset))  # 90% for training\n",
    "val_size = len(total_dataset) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(total_dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=T4.args.batch_size, shuffle=False, num_workers=2,\n",
    "                              drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=T4.args.batch_size, shuffle=False, num_workers=2, drop_last=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Encoder = T4.LogSigRNNEncoder(**T4.encoder_config).to(T4.args.device)\n",
    "Decoder = T4.TimesFormerDecoder(**T4.decoder_config).to(T4.args.device)\n",
    "Supervisor = T4.ModernTCN(T4.supervisor_config).to(T4.args.device)\n",
    "Generator = T4.LogSigRNNGenerator(**T4.logsig_config).to(T4.args.device)\n",
    "Discriminator = T4.tailGANDiscriminator(T4.discriminator_config).to(T4.args.device)\n",
    "model = T4.T4sigWGAN(Encoder, Decoder, Generator, Supervisor, Discriminator, T4.args.batch_size).to(T4.args.device)\n",
    "trainer = T4.FinetuneTrainer(T4.args, model, train_dataloader, val_dataloader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "stage = \"Pretrain_1\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('RMSE_loss_for_ER')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save(stage)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stage = \"Pretrain_2\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('SigW1_supervisor_loss_for_S')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save(stage)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stage = \"Finetune\"\n",
    "\n",
    "# model training\n",
    "for epoch in tqdm(range(T4.args.epochs)):\n",
    "    trainer.train(epoch, stage)\n",
    "    val_loss = trainer.valid(epoch, stage)\n",
    "\n",
    "# train log image save\n",
    "trainer.evaluate('SigW1_supervisor_loss + RMSE_for_SR')\n",
    "trainer.evaluate_tail('loss_D and loss_G + SigW1_generator_loss')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save(stage)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_fake = model(600)\n",
    "stacked = torch.stack([total_dataset[i] for i in range(600)])\n",
    "x_real = stacked\n",
    "T4.plot_summary(x_fake=x_fake.detach(), x_real=x_real.detach(), trainer=\"T4sigWGAN\", G=\"LogSigRNN\")\n",
    "plt.savefig('./result/T4sigWGAN.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 1.5), dpi=400)\n",
    "plt.plot(x_fake.detach().cpu().numpy()[1][:, 1], label=\"Fake\")\n",
    "plt.plot(total_dataset[1].detach().cpu().numpy()[:, 1], label=\"Real\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# metric_iteration = 5\n",
    "#\n",
    "# discriminative_score = list()\n",
    "# for _ in range(metric_iteration):\n",
    "#     temp_disc = T4.discriminative_score_metrics(ori_data, generated_data)\n",
    "#     discriminative_score.append(temp_disc)\n",
    "#\n",
    "# print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))\n",
    "#\n",
    "#\n",
    "# predictive_score = list()\n",
    "# for tt in range(metric_iteration):\n",
    "#     temp_pred = T4.predictive_score_metrics(ori_data, generated_data)\n",
    "#     predictive_score.append(temp_pred)\n",
    "#\n",
    "# print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))\n",
    "#\n",
    "#\n",
    "# T4.visualization(ori_data, generated_data, 'pca')\n",
    "# T4.visualization(ori_data, generated_data, 'tsne')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
