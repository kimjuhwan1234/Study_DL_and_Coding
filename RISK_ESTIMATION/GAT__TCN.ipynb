{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 실행 준비"
   ],
   "metadata": {
    "id": "uSGwEK8Rl8nu"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "poEZQtkOdvnF"
   },
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "id": "DSgYsaX5g5s9",
    "ExecuteTime": {
     "end_time": "2025-05-09T02:51:45.387922Z",
     "start_time": "2025-05-09T02:51:45.108882Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "file_path = '/content/daily_all.csv'\n",
    "df = pd.read_csv(file_path, engine='pyarrow')"
   ],
   "metadata": {
    "id": "-vyn0-Vqghaa"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"daily_all.csv\")"
   ],
   "metadata": {
    "id": "i2zflSUtie6r"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "24-DKqOjhCyk",
    "outputId": "74670461-cca7-4e0e-dc2b-c5523b9a55c9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터셋 로드"
   ],
   "metadata": {
    "id": "ng-ZikeSl_o9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 피처 선택"
   ],
   "metadata": {
    "id": "ssYDGmrLq16F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "company_name = \"AMZN\"  # 예측할 회사 선택\n",
    "\n",
    "# 데이터 선택: 종가는 모든 회사에 대해, 거래량과 감정분석은 예측할 회사만\n",
    "data = df[[f'prccd_{company}' for company in ['TSLA', 'NVDA', 'MSFT', 'GOOG', 'AAPL', 'DIS', 'XOM', 'CRM', 'INTC', 'AMZN']] +\n",
    "          [f'cshtrd_{company_name}', f'sent_{company_name}', 'datadate']].copy()\n",
    "data.set_index('datadate', inplace=True)\n",
    "\n",
    "# 예측 회사의 상승/하락 결과 (1: 상승, 0: 하락) : GAT에서 사용 X\n",
    "# data.loc[:, 'y'] = (df[f'prccd_{company_name}'] > df[f'prccd_{company_name}'].shift(1)).astype(int)\n",
    "# data = data[1:] # 첫 번째 행은 상승/하락 정보를 알 수 없으므로 제거\n",
    "\n",
    "# 감정분석 결측값을 0으로 채움\n",
    "data.fillna(0, inplace=True)  # 기존 sent에는 NaN이 너무 많음; 임베딩도 NaN으로 출력됨\n",
    "\n",
    "# 결과 출력\n",
    "data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "NvkAcJ2yd59z",
    "outputId": "b103f9e4-61c5-4589-86a2-7eb065d836f4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data.isna().sum()"
   ],
   "metadata": {
    "id": "0h0OYum5RzC6",
    "outputId": "75c4f819-1ca2-4541-d3ad-3fe72e048c2f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GAT"
   ],
   "metadata": {
    "id": "c3a9pQD5FCYz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 노드 : 각 시점\n",
    "- 피처 : 10개 주식 종가 + 예측 기업 감정분석\n",
    "- GAT의 역할 : 피처들의 관계(회사 간의 관계 등)을 파악해 **시점별** 임베딩 생성;  다른 시점과의 연관성을 반영    \n",
    "(ex. 1~10일 전과 연결이 되어있는 상태에서, 1일 전 정보는 얼마나 중요하고 10일 전 정보는 얼마나 중요한지 판단)"
   ],
   "metadata": {
    "id": "ZyPD4n10nlku"
   }
  },
  {
   "metadata": {
    "id": "zcWtyQhmENfe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "outputId": "23fe19b7-0e16-4b58-cfa0-231956c66a69",
    "ExecuteTime": {
     "end_time": "2025-05-08T05:54:22.472327Z",
     "start_time": "2025-05-08T05:54:01.325989Z"
    }
   },
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# PyTorch Geometric 설치\n",
    "!pip install torch-geometric\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu111.html\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import 문\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATv2Conv"
   ],
   "metadata": {
    "id": "hKYw4OJfKP-A",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "outputId": "b8c7e34f-c825-4e62-9f01-2d54658bed35",
    "ExecuteTime": {
     "end_time": "2025-05-09T02:51:42.485281Z",
     "start_time": "2025-05-09T02:51:41.341213Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# GAT 레이어 정의\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, heads=4):\n",
    "        super().__init__()\n",
    "        self.gat = GATv2Conv(in_features, out_features, heads=heads, concat=False) # 선형 변환 : concat이 True이면 결합, False이면 평균\n",
    "                                                                                   # GATv2Conv 내부에서 어텐션 계산이 수행됨\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.gat(x, edge_index)"
   ],
   "metadata": {
    "id": "OeUAFsolD3_n"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 데이터 준비\n",
    "node_features = data.values  # shape: [날짜 수, feature 수]\n",
    "n_nodes = node_features.shape[0] # 노드 수 (==날짜 수)\n",
    "\n",
    "# 그래프 형태로 변환 : 엣지 생성 (시점 간 연결)\n",
    "edge_list = []\n",
    "for i in range(n_nodes):\n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]: # 이후 시점들에 단방향 연결; (휴장 같은 것은 생각하지 않음.... 시점 기준)\n",
    "        if i + j < n_nodes:\n",
    "            edge_list.append([i, i + j])\n",
    "edge_index = torch.tensor(edge_list).t()"
   ],
   "metadata": {
    "id": "q8GV9ihbilPA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "edge_index # 출력 결과의 첫째행이 출발노드, 둘째행이 도착노드!"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoPQPC7lqhYP",
    "outputId": "f4422a70-13fd-4966-e6ba-664c8e8354f7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# GAT 입력 형태로 변환\n",
    "x = torch.tensor(node_features, dtype=torch.float)"
   ],
   "metadata": {
    "id": "QHYMVczGi_Ey"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# GAT 모델 생성 및 실행\n",
    "gat_model = GATLayer(in_features=data.shape[1], out_features=8) # 결과: 각 시점(노드)에 대한 (output_features)차원 임베딩\n",
    "embeddings = gat_model(x, edge_index)  # shape: [날짜 수, 설정한 out_features 수]"
   ],
   "metadata": {
    "id": "fjZPQBOtDDlR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y20jeOXzKiQE",
    "outputId": "492af6b7-4c9a-436a-d480-50b904f861ad"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# csv로 저장"
   ],
   "metadata": {
    "id": "6Qc2aXFfaIms"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings_np = embeddings.detach().cpu().numpy()\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_embeddings = pd.DataFrame(embeddings_np)\n",
    "\n",
    "# data의 인덱스(datadate)를 가져와서 추가 (data는 이미 set_index로 datadate를 인덱스로 설정했음)\n",
    "df_embeddings['datadate'] = data.index.values\n",
    "\n",
    "# 컬럼 이름 설정\n",
    "column_names = [f'emb_{i}' for i in range(embeddings_np.shape[1])]\n",
    "df_embeddings.columns = column_names + ['datadate']\n",
    "\n",
    "# datadate를 첫 번째 컬럼으로 이동\n",
    "df_embeddings = df_embeddings[['datadate'] + column_names]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Embeddings with datadate:\")\n",
    "print(df_embeddings.head())"
   ],
   "metadata": {
    "id": "L1bGXzBpaJtx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4a9c94e5-49ab-4827-efa3-6089c3edf7ae"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# CSV로 저장\n",
    "df_embeddings.to_csv(f'embeddings_{company_name}.csv', index=False)"
   ],
   "metadata": {
    "id": "QdlV3Fhjs0mb"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install optuna"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "iBDOkaCDuMsI",
    "outputId": "43349298-cdff-4b98-fc36-3d32e345734c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "###TCN 시작"
   ],
   "metadata": {
    "id": "Yu936WwLjWyW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "# --- 유틸 함수 ---\n",
    "def get_conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias):\n",
    "    return nn.Conv1d(in_channels=in_channels, out_channels=out_channels,\n",
    "                     kernel_size=kernel_size, stride=stride,\n",
    "                     padding=padding, dilation=dilation,\n",
    "                     groups=groups, bias=bias)\n",
    "\n",
    "def get_bn(channels):\n",
    "    return nn.BatchNorm1d(channels)\n",
    "\n",
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups, dilation=1, bias=False):\n",
    "    if padding is None:\n",
    "        padding = kernel_size // 2\n",
    "    result = nn.Sequential()\n",
    "    result.add_module('conv', get_conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias))\n",
    "    result.add_module('bn', get_bn(out_channels))\n",
    "    return result\n",
    "\n",
    "# --- RevIN ---\n",
    "class RevIN(nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def _init_params(self):\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def forward(self, x, mode: str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        return x\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim - 1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:, -1:, :].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        x = (x - self.mean) / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight[None, None, :] + self.affine_bias[None, None, :]\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias[None, None, :]) / self.affine_weight[None, None, :]\n",
    "        x = x * self.stdev + self.mean\n",
    "        return x\n",
    "\n",
    "# --- 시계열 분해 ---\n",
    "class moving_avg(nn.Module):\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        return x - moving_mean, moving_mean\n",
    "\n",
    "# --- 커스텀 커널 ---\n",
    "class ReparamLargeKernelConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, small_kernel, small_kernel_merged=False):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.small_kernel = small_kernel\n",
    "        padding = kernel_size // 2\n",
    "        if small_kernel_merged:\n",
    "            self.lkb_reparam = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, groups=groups, bias=True)\n",
    "        else:\n",
    "            self.lkb_origin = conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups)\n",
    "            if small_kernel is not None:\n",
    "                self.small_conv = conv_bn(in_channels, out_channels, small_kernel, stride, small_kernel // 2, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'lkb_reparam'):\n",
    "            return self.lkb_reparam(x)\n",
    "        out = self.lkb_origin(x)\n",
    "        if hasattr(self, 'small_conv'):\n",
    "            out += self.small_conv(x)\n",
    "        return out\n",
    "\n",
    "# --- 출력층 ---\n",
    "class Flatten_Head(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):         # x: [B, C, T]\n",
    "        x = x.permute(0, 2, 1)    # → [B, T, C]\n",
    "        x = self.linear(x)        # → [B, T, 1]\n",
    "        return x.squeeze(-1)     # → [B, T]\n",
    "\n",
    "# --- ModernTCN 모델 ---\n",
    "class ModernTCN(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.revin = RevIN(configs.enc_in, affine=configs.affine) if configs.revin else None\n",
    "        self.decomp = series_decomp(configs.kernel_size) if configs.decomposition else None\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.norm_layers = nn.ModuleList()\n",
    "\n",
    "        c_in = configs.enc_in\n",
    "        for i in range(len(configs.dims)):\n",
    "            conv = ReparamLargeKernelConv(c_in, configs.dims[i],\n",
    "                                          kernel_size=configs.large_size[i],\n",
    "                                          stride=1,\n",
    "                                          groups=1,\n",
    "                                          small_kernel=configs.small_size[i],\n",
    "                                          small_kernel_merged=configs.small_kernel_merged)\n",
    "            self.conv_layers.append(conv)\n",
    "            self.norm_layers.append(nn.BatchNorm1d(configs.dims[i]))\n",
    "            c_in = configs.dims[i]\n",
    "\n",
    "        self.head = Flatten_Head(configs.dims[-1])\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, C]\n",
    "        if self.revin:\n",
    "            x = self.revin(x, 'norm')\n",
    "        if self.decomp:\n",
    "            x, _ = self.decomp(x)\n",
    "        x = x.permute(0, 2, 1)  # [B, C, T]\n",
    "        for conv, norm in zip(self.conv_layers, self.norm_layers):\n",
    "            x = conv(x)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "        out = self.head(x)  # [B, T]\n",
    "        return out\n",
    "\n",
    "# --- Config 클래스 ---\n",
    "class Configs:\n",
    "    def __init__(self, enc_in):\n",
    "        self.enc_in = enc_in\n",
    "        self.dims = [8,16, 32]\n",
    "        self.large_size = [5, 5, 3]\n",
    "        self.small_size = [5, 3, 3]\n",
    "        self.small_kernel_merged = False\n",
    "        self.dropout = 0.1\n",
    "        self.head_dropout = 0.2\n",
    "        self.revin = True\n",
    "        self.affine = True\n",
    "        self.decomposition = True\n",
    "        self.kernel_size = 25\n"
   ],
   "metadata": {
    "id": "SGY079rGizbs"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "###학습 및 OPTUNA"
   ],
   "metadata": {
    "id": "LyXr4lYwuEJW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score # Import f1_score\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=30, lr=1e-3,pos_weight=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
    "    train_losses, val_losses, val_accs = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 1. 학습 단계\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_output = model(X_train).squeeze(0)  # → [T]\n",
    "        train_output = train_output.detach().clone().requires_grad_(True)  # detach + clone + requires_grad 복구\n",
    "        loss = criterion(train_output, y_train.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # 2. 검증 단계\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output = model(X_val).squeeze(0)\n",
    "            val_loss = criterion(val_output, y_val.float()).item()\n",
    "            pred = (torch.sigmoid(val_output) > 0.5).int()\n",
    "            acc = (pred == y_val).float().mean().item()\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(acc)\n",
    "\n",
    "        print(f\"[{epoch+1}/{epochs}] Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Val Acc: {acc:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accs"
   ],
   "metadata": {
    "collapsed": true,
    "id": "QQZdcTXzmrGn"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Config class 내부를 trial 기반으로 생성\n",
    "def objective(trial):\n",
    "    dims = [\n",
    "        trial.suggest_categorical(\"dim1\", [8, 16, 32, 64]),\n",
    "        trial.suggest_categorical(\"dim2\", [16, 32, 64, 128]),\n",
    "        trial.suggest_categorical(\"dim3\", [32, 64, 128, 256])\n",
    "    ]\n",
    "    large_size = [\n",
    "        trial.suggest_categorical(\"k1\", [3, 5, 7, 9, 11]),\n",
    "        trial.suggest_categorical(\"k2\", [3, 5, 7, 9]),\n",
    "        trial.suggest_categorical(\"k3\", [3, 5, 7])\n",
    "    ]\n",
    "    small_size = [\n",
    "        trial.suggest_categorical(\"s1\", [1, 3, 5]),\n",
    "        trial.suggest_categorical(\"s2\", [1, 3]),\n",
    "        trial.suggest_categorical(\"s3\", [1, 3])\n",
    "    ]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "    head_dropout = trial.suggest_float(\"head_dropout\", 0.0, 0.3)\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [5, 11, 15, 25, 31])\n",
    "    decomposition = trial.suggest_categorical(\"decomposition\", [True, False])\n",
    "    revin = trial.suggest_categorical(\"revin\", [True, False])\n",
    "    affine = trial.suggest_categorical(\"affine\", [True, False])\n",
    "\n",
    "    class TrialConfig:\n",
    "        def __init__(self):\n",
    "            self.enc_in = X_train.shape[2]\n",
    "            self.dims = dims\n",
    "            self.large_size = large_size\n",
    "            self.small_size = small_size\n",
    "            self.small_kernel_merged = False\n",
    "            self.dropout = dropout\n",
    "            self.head_dropout = head_dropout\n",
    "            self.revin = revin\n",
    "            self.affine = affine\n",
    "            self.decomposition = decomposition\n",
    "            self.kernel_size = kernel_size\n",
    "\n",
    "    model = ModernTCN(TrialConfig())\n",
    "    #_, _, val_accs = train_model(model, X_train, y_train, X_val, y_val, epochs=15)\n",
    "    #return max(val_accs)  # Accuracy 기준 최적화\n",
    "\n",
    "   #pos_weight 계산 (불균형 데이터 보정)\n",
    "    pos_weight = torch.tensor([(y_train == 0).sum() / (y_train == 1).sum()]).to(y_train.device)\n",
    "\n",
    "    #모델 학습 (loss에 pos_weight 반영됨)\n",
    "    train_model(model, X_train, y_train, X_val, y_val, epochs=15, pos_weight=pos_weight)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_val).squeeze(0)\n",
    "        probs = torch.sigmoid(pred).cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "\n",
    "    y_true = y_val.cpu().numpy()\n",
    "    return f1_score(y_true, preds)\n",
    "\n",
    "\n",
    "# Optuna 튜닝 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적 하이퍼파라미터 출력\n",
    "print(\"✅ Best Trial:\")\n",
    "print(study.best_trial.params)\n",
    "best_params = study.best_trial.params"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzU3cvtAz1Bl",
    "outputId": "95b76a16-5918-43f7-84af-b493f4c42865"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "###시각화 코드"
   ],
   "metadata": {
    "id": "Rg-yp_utuBji"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_training(train_losses, val_losses, val_accs):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.legend(); plt.title(\"Loss over Epochs\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(val_accs, label='Val Accuracy')\n",
    "    plt.legend(); plt.title(\"Validation Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_prediction(pred_probs, true_labels):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(true_labels, label='True')\n",
    "    plt.plot(pred_probs, label='Pred (sigmoid)', alpha=0.7)\n",
    "    plt.legend(); plt.title(\"Prediction vs True\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_cumulative_return(pred_probs, true_labels, prices):\n",
    "    signal = (pred_probs > 0.5).astype(int)\n",
    "    returns = (prices[1:] / prices[:-1]) - 1\n",
    "    strategy_returns = returns * signal[:-1]  # 예측한 시점의 다음날 수익\n",
    "\n",
    "    cumulative = (strategy_returns + 1).cumprod()\n",
    "    market = (returns + 1).cumprod()\n",
    "\n",
    "    plt.plot(cumulative, label='Strategy')\n",
    "    plt.plot(market, label='Market (buy & hold)')\n",
    "    plt.legend(); plt.title(\"Cumulative Return\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "id": "NRsQNf3tuBNM"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_seed(42)\n",
    "\n",
    "# 1. 라벨 생성\n",
    "close_prices = data[f'prccd_{company_name}'].values\n",
    "returns = (close_prices[1:] / close_prices[:-1]) - 1\n",
    "labels = np.where(returns > 0.003, 1, 0)  # 0.3% 초과만 1로\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# 2. GAT 임베딩 → TCN 입력 형태로 변환\n",
    "embeddings = embeddings[:-1]  # 라벨과 길이 맞춤\n",
    "tcn_input = embeddings.unsqueeze(0)  # [1, T, C]\n",
    "\n",
    "# ✅ 3. 길이 맞춰주기 (가장 중요)\n",
    "min_len = min(tcn_input.shape[1], labels.shape[0])\n",
    "tcn_input = tcn_input[:, :min_len, :]\n",
    "labels = labels[:min_len]\n",
    "\n",
    "# 3. 학습/검증 데이터 분할\n",
    "seq_len = tcn_input.shape[1]\n",
    "split = int(seq_len * 0.8)\n",
    "X_train = tcn_input[:, :split, :]\n",
    "X_val   = tcn_input[:, split:, :]\n",
    "y_train = labels[:split]\n",
    "y_val   = labels[split:]\n",
    "\n",
    "class BestConfig:\n",
    "    def __init__(self):\n",
    "        self.enc_in = X_train.shape[2]\n",
    "        self.dims = [best_params['dim1'], best_params['dim2'], best_params['dim3']]\n",
    "        self.large_size = [best_params['k1'], best_params['k2'], best_params['k3']]\n",
    "        self.small_size = [best_params['s1'], best_params['s2'], best_params['s3']]\n",
    "        self.small_kernel_merged = False\n",
    "        self.dropout = best_params['dropout']\n",
    "        self.head_dropout = best_params['head_dropout']\n",
    "        self.revin = best_params['revin']\n",
    "        self.affine = best_params['affine']\n",
    "        self.decomposition = best_params['decomposition']\n",
    "        self.kernel_size = best_params['kernel_size']\n",
    "\n",
    "# 4. 모델 생성 및 학습\n",
    "model = ModernTCN(BestConfig())\n",
    "\n",
    "train_losses, val_losses, val_accs = train_model(model,\n",
    "X_train, y_train, X_val, y_val, epochs=100,lr=1e-2)\n",
    "\n",
    "# 5. 예측 및 시각화\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_logits = model(X_val).squeeze(0)  # [1, T] → [T]\n",
    "    pred_probs = torch.sigmoid(pred_logits).cpu().numpy()\n",
    "    pred_labels = (pred_probs > 0.5).astype(int)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "\"\"\"\n",
    "# 1. 실제 라벨\n",
    "true_labels = y_val.cpu().numpy()\n",
    "\n",
    "# 2. 다양한 threshold에 대해 f1-score 측정\n",
    "precisions, recalls, thresholds = precision_recall_curve(true_labels, pred_probs)\n",
    "\n",
    "f1s = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)  # f1-score 계산\n",
    "best_idx = np.argmax(f1s)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"✅ Best threshold by F1-score: {best_threshold:.4f}, F1: {f1s[best_idx]:.4f}\")\n",
    "\n",
    "# 3. 최적 threshold로 예측 라벨 생성\n",
    "pred_labels = (pred_probs > best_threshold).astype(int)\n",
    "# 6. 누적 수익률 (선택)\n",
    "# future_prices = close_prices[split+1:]  # 실제 수익률 계산용\n",
    "# visualize_cumulative_return(pred_probs, y_val.cpu().numpy(), future_prices)\n",
    "\"\"\"\n",
    "\n",
    "visualize_training(train_losses, val_losses, val_accs)\n",
    "visualize_prediction(pred_probs, y_val.cpu().numpy())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UCzrQgDimtsc",
    "outputId": "c1bbea0f-9c47-419e-c12f-f2779cb67478"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#정확도 기반\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_val.cpu(), pred_labels))\n",
    "print(confusion_matrix(y_val.cpu(), pred_labels))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFx060ibp0FO",
    "outputId": "0ca39b7e-6e35-416c-8c5f-c3bfaee96307"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#f1 score 기반\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_val.cpu(), pred_labels))\n",
    "print(confusion_matrix(y_val.cpu(), pred_labels))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gLZn6L2wV4s",
    "outputId": "9b454dfc-6de4-4c27-807d-bbc3b7715c56"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "unique, counts = np.unique(labels.numpy(), return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V74w7Uqz3k2i",
    "outputId": "ac3053d3-fc94-4d0f-e9c2-6561d6e2019e"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
