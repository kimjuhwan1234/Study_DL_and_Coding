{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T06:06:47.060379Z",
     "start_time": "2025-05-01T06:06:45.562382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import argparse\n",
    "from os import path as pt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib import ALGOS\n",
    "from lib.utils import pickle_it\n",
    "from lib.algos.base import BaseConfig\n",
    "from lib.data import get_data2\n",
    "from hyperparameters import SIGCWGAN_CONFIGS\n",
    "from lib.plot import savefig, create_summary\n",
    "\n",
    "gc.collect()"
   ],
   "id": "1aa943b524320997",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T04:13:41.474595Z",
     "start_time": "2025-05-01T04:13:41.458625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_algo_config(dataset, data_params):\n",
    "    \"\"\" Get the algorithms parameters. \"\"\"\n",
    "    key = dataset\n",
    "    if dataset == 'VAR':\n",
    "        key += str(data_params['dim'])\n",
    "    elif dataset == 'STOCKS':\n",
    "        key += '_' + '_'.join(data_params['assets'])\n",
    "    return SIGCWGAN_CONFIGS[key]\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def get_algo(algo_id, base_config, dataset, data_params, x_real):\n",
    "    if algo_id == 'SigCWGAN':\n",
    "        algo_config = get_algo_config(dataset, data_params)\n",
    "        algo = ALGOS[algo_id](x_real=x_real, config=algo_config, base_config=base_config)\n",
    "    else:\n",
    "        algo = ALGOS[algo_id](x_real=x_real, base_config=base_config)\n",
    "    return algo\n",
    "\n",
    "\n",
    "# def run(algo_id, base_config, dataset, data_params={}):\n",
    "#     \"\"\" Create the experiment directory, calibrate algorithm, store relevant parameters. \"\"\"\n",
    "#     experiment_directory = f'./numerical_results/{dataset}/stock/seed=0/SigCWGAN'\n",
    "#\n",
    "#     df_2 = get_dataset_configuration()\n",
    "#     x_real = get_data2(df_2.values.reshape(1, -1, 10), base_config.p, base_config.q)\n",
    "#     x_real = x_real.to(base_config.device)\n",
    "#     ind_train = int(x_real.shape[0] * 0.8)\n",
    "#     x_real_train, x_real_test = x_real[:ind_train], x_real[ind_train:]  #train_test_split(x_real, train_size = 0.8)\n",
    "#\n",
    "#     algo = get_algo(algo_id, base_config, dataset, data_params, x_real_train)\n",
    "#     # Train the algorithm\n",
    "#     algo.fit()\n",
    "#     # create summary\n",
    "#     create_summary(dataset, base_config.device, algo.G, base_config.p, base_config.q, x_real_test)\n",
    "#     savefig('summary.png', experiment_directory)\n",
    "#     x_fake = create_summary(dataset, base_config.device, algo.G, base_config.p, 8000, x_real_test, one=True)\n",
    "#     print(x_fake.shape)\n",
    "#     savefig('summary_long.png', experiment_directory)\n",
    "#     plt.plot(x_fake.cpu().numpy()[0, :2000])\n",
    "#     savefig('long_path.png', experiment_directory)\n",
    "#     # Pickle generator weights, real path and hyperparameters.\n",
    "#     pickle_it(x_real, pt.join(pt.dirname(experiment_directory), 'x_real.torch'))\n",
    "#     pickle_it(x_real_test, pt.join(pt.dirname(experiment_directory), 'x_real_test.torch'))\n",
    "#     pickle_it(x_real_train, pt.join(pt.dirname(experiment_directory), 'x_real_train.torch'))\n",
    "#     pickle_it(algo.training_loss, pt.join(experiment_directory, 'training_loss.pkl'))\n",
    "#     pickle_it(algo.G.to('cpu').state_dict(), pt.join(experiment_directory, 'G_weights.torch'))\n",
    "#     # Log some results at the end of training\n",
    "#     algo.plot_losses()\n",
    "#     savefig('losses.png', experiment_directory)\n",
    "\n",
    "\n",
    "def get_dataset_configuration():\n",
    "    price_df = pd.read_csv('./data/sp500.csv')\n",
    "    price_df.set_index('datadate', inplace=True)\n",
    "    df_0 = price_df[['AAPL', 'DIS', 'XOM', 'INTC', 'MSFT', 'AMZN', 'NVDA', 'CRM', 'GOOGL', 'TSLA']]\n",
    "    df_1 = df_0.dropna(axis=0)\n",
    "    df_2 = df_1.pct_change().dropna()\n",
    "    return df_2"
   ],
   "id": "b5d9f73aae70a099",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T04:13:46.877135Z",
     "start_time": "2025-05-01T04:13:46.844972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# Meta parameters\n",
    "parser.add_argument('-base_dir', default='./numerical_results', type=str)\n",
    "parser.add_argument('-use_cuda', default=1, action='store_true')\n",
    "parser.add_argument('-device', default=0, type=int)\n",
    "parser.add_argument('-num_seeds', default=1, type=int)\n",
    "parser.add_argument('-initial_seed', default=0, type=int)\n",
    "#parser.add_argument('-datasets', default=['ARCH', 'STOCKS', 'ECG', 'VAR', ], nargs=\"+\")\n",
    "parser.add_argument('-datasets', default=['STOCKS', 'ARCH', 'VAR', ], nargs=\"+\")\n",
    "parser.add_argument('-algos', default=['SigCWGAN', 'GMMN', 'RCGAN', 'TimeGAN', 'RCWGAN', 'CWGAN', ], nargs=\"+\")\n",
    "\n",
    "# Algo hyperparameters\n",
    "parser.add_argument('-batch_size', default=256, type=int)\n",
    "parser.add_argument('-p', default=20, type=int)\n",
    "parser.add_argument('-q', default=5, type=int)\n",
    "parser.add_argument('-hidden_dims', default=5 * (128,), type=tuple)\n",
    "parser.add_argument('-total_steps', default=2500, type=int)\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "base_config = BaseConfig(\n",
    "    device='cuda:{}'.format(args.device) if args.use_cuda and torch.cuda.is_available() else 'cpu',\n",
    "    batch_size=args.batch_size,\n",
    "    hidden_dims=args.hidden_dims,\n",
    "    seed=0,\n",
    "    p=args.p,\n",
    "    q=args.q,\n",
    "    total_steps=args.total_steps,\n",
    "    mc_samples=1000,\n",
    ")\n",
    "\n",
    "data_params = {'dim': 10}\n",
    "base_config.device"
   ],
   "id": "e66f94a6e769be6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T05:40:29.171835Z",
     "start_time": "2025-05-01T04:13:49.751298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_directory = f'./numerical_results/VAR/stock/seed=0/SigCWGAN'\n",
    "os.makedirs(experiment_directory, exist_ok=True)\n",
    "df_2 = get_dataset_configuration()\n",
    "print(len(df_2))\n",
    "x_real = get_data2(df_2.values.reshape(1, -1, 10), base_config.p, base_config.q)\n",
    "x_real = x_real.to(base_config.device)\n",
    "ind_train = int(x_real.shape[0] * 0.8)\n",
    "x_real_train, x_real_test = x_real[:ind_train], x_real[ind_train:]  #train_test_split(x_real, train_size = 0.8)\n",
    "\n",
    "algo = get_algo('SigCWGAN', base_config, 'VAR', data_params, x_real_train)\n",
    "# Train the algorithm\n",
    "algo.fit()\n",
    "# create summary\n",
    "create_summary('VAR', base_config.device, algo.G, base_config.p, base_config.q, x_real_test)\n",
    "savefig('summary.png', experiment_directory)\n",
    "x_fake = create_summary('VAR', base_config.device, algo.G, base_config.p, 8000, x_real_test, one=True)\n",
    "print(x_fake.shape)\n",
    "savefig('summary_long.png', experiment_directory)\n",
    "plt.plot(x_fake.cpu().numpy()[0, :2000])\n",
    "savefig('long_path.png', experiment_directory)\n",
    "# Pickle generator weights, real path and hyperparameters.\n",
    "pickle_it(x_real, pt.join(pt.dirname(experiment_directory), 'x_real.torch'))\n",
    "pickle_it(x_real_test, pt.join(pt.dirname(experiment_directory), 'x_real_test.torch'))\n",
    "pickle_it(x_real_train, pt.join(pt.dirname(experiment_directory), 'x_real_train.torch'))\n",
    "pickle_it(algo.training_loss, pt.join(experiment_directory, 'training_loss.pkl'))\n",
    "pickle_it(algo.G.to('cpu').state_dict(), pt.join(experiment_directory, 'G_weights.torch'))\n",
    "# Log some results at the end of training\n",
    "algo.plot_losses()\n",
    "savefig('losses.png', experiment_directory)"
   ],
   "id": "4be84c4825acf04c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2500/2500 [1:26:20<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8000, 10])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T03:59:58.688373Z",
     "start_time": "2025-05-01T03:59:58.672585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataset_configuration2(path):\n",
    "    price_df = pd.read_parquet(path)\n",
    "    df_0 = price_df[\n",
    "        ['prccd', 'cshtrd', 'absacc', 'acc', 'aeavol', 'agr', 'baspread', 'beta', 'cashpr', 'cfp', 'chmom', 'chtx',\n",
    "         'ear', 'retvol', 'tb', 'turn']]\n",
    "    df_1 = df_0.dropna(axis=0)\n",
    "    return df_1"
   ],
   "id": "11922f574381747f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T04:07:11.223159Z",
     "start_time": "2025-05-01T03:59:58.704456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = './data/monthly_pricewithcharacteristics'\n",
    "for tic in os.listdir(ROOT_DIR):\n",
    "    \"\"\" Create the experiment directory, calibrate algorithm, store relevant parameters. \"\"\"\n",
    "    company = tic.split('.')[0]\n",
    "    experiment_directory = f'./numerical_results/{company}/stock/seed=0/SigCWGAN'\n",
    "    os.makedirs(experiment_directory, exist_ok=True)\n",
    "    df_2 = get_dataset_configuration2(os.path.join(ROOT_DIR, tic))\n",
    "    print(len(df_2))\n",
    "    x_real = get_data2(df_2.values.reshape(1, -1, 16), base_config.p, base_config.q)\n",
    "    x_real = x_real.to(base_config.device)\n",
    "    ind_train = int(x_real.shape[0] * 0.8)\n",
    "    x_real_train, x_real_test = x_real[:ind_train], x_real[ind_train:]  #train_test_split(x_real, train_size = 0.8)\n",
    "\n",
    "    algo = get_algo('SigCWGAN', base_config, 'VAR', data_params, x_real_train)\n",
    "    # Train the algorithm\n",
    "    algo.fit()\n",
    "    # create summary\n",
    "    create_summary(company, base_config.device, algo.G, base_config.p, base_config.q, x_real_test)\n",
    "    savefig('summary.png', experiment_directory)\n",
    "    x_fake = create_summary(company, base_config.device, algo.G, base_config.p, 8000, x_real_test, one=True)\n",
    "    print(x_fake.shape)\n",
    "    savefig('summary_long.png', experiment_directory)\n",
    "    plt.plot(x_fake.cpu().numpy()[0, :2000])\n",
    "    savefig('long_path.png', experiment_directory)\n",
    "    # Pickle generator weights, real path and hyperparameters.\n",
    "    pickle_it(x_real, pt.join(pt.dirname(experiment_directory), 'x_real.torch'))\n",
    "    pickle_it(x_real_test, pt.join(pt.dirname(experiment_directory), 'x_real_test.torch'))\n",
    "    pickle_it(x_real_train, pt.join(pt.dirname(experiment_directory), 'x_real_train.torch'))\n",
    "    pickle_it(algo.training_loss, pt.join(experiment_directory, 'training_loss.pkl'))\n",
    "    pickle_it(algo.G.to('cpu').state_dict(), pt.join(experiment_directory, 'G_weights.torch'))\n",
    "    # Log some results at the end of training\n",
    "    algo.plot_losses()\n",
    "    savefig('losses.png', experiment_directory)"
   ],
   "id": "549c37058d4b40d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [06:15<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8000, 16])\n",
      "372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                      | 16/200 [00:33<06:21,  2.07s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
